{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8142,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018422991893883568,
      "grad_norm": 0.4681312143802643,
      "learning_rate": 4.9699091132399905e-05,
      "loss": 0.3673,
      "step": 50
    },
    {
      "epoch": 0.036845983787767135,
      "grad_norm": 0.404188334941864,
      "learning_rate": 4.9392041267501844e-05,
      "loss": 0.163,
      "step": 100
    },
    {
      "epoch": 0.0552689756816507,
      "grad_norm": 0.2875608205795288,
      "learning_rate": 4.908499140260378e-05,
      "loss": 0.1526,
      "step": 150
    },
    {
      "epoch": 0.07369196757553427,
      "grad_norm": 0.27985048294067383,
      "learning_rate": 4.877794153770572e-05,
      "loss": 0.1515,
      "step": 200
    },
    {
      "epoch": 0.09211495946941783,
      "grad_norm": 0.3679773509502411,
      "learning_rate": 4.847089167280767e-05,
      "loss": 0.1505,
      "step": 250
    },
    {
      "epoch": 0.1105379513633014,
      "grad_norm": 0.27076172828674316,
      "learning_rate": 4.816384180790961e-05,
      "loss": 0.1426,
      "step": 300
    },
    {
      "epoch": 0.12896094325718496,
      "grad_norm": 0.27733486890792847,
      "learning_rate": 4.7856791943011546e-05,
      "loss": 0.1353,
      "step": 350
    },
    {
      "epoch": 0.14738393515106854,
      "grad_norm": 0.31495535373687744,
      "learning_rate": 4.754974207811349e-05,
      "loss": 0.1271,
      "step": 400
    },
    {
      "epoch": 0.1658069270449521,
      "grad_norm": 0.2632845938205719,
      "learning_rate": 4.724269221321543e-05,
      "loss": 0.1209,
      "step": 450
    },
    {
      "epoch": 0.18422991893883567,
      "grad_norm": 0.36149898171424866,
      "learning_rate": 4.693564234831737e-05,
      "loss": 0.1114,
      "step": 500
    },
    {
      "epoch": 0.20265291083271925,
      "grad_norm": 0.2917562425136566,
      "learning_rate": 4.662859248341931e-05,
      "loss": 0.1164,
      "step": 550
    },
    {
      "epoch": 0.2210759027266028,
      "grad_norm": 0.4353247582912445,
      "learning_rate": 4.6321542618521254e-05,
      "loss": 0.1082,
      "step": 600
    },
    {
      "epoch": 0.23949889462048637,
      "grad_norm": 0.3192460536956787,
      "learning_rate": 4.601449275362319e-05,
      "loss": 0.1078,
      "step": 650
    },
    {
      "epoch": 0.2579218865143699,
      "grad_norm": 0.3323412239551544,
      "learning_rate": 4.570744288872513e-05,
      "loss": 0.1013,
      "step": 700
    },
    {
      "epoch": 0.2763448784082535,
      "grad_norm": 0.37939801812171936,
      "learning_rate": 4.540039302382707e-05,
      "loss": 0.1026,
      "step": 750
    },
    {
      "epoch": 0.2947678703021371,
      "grad_norm": 0.4147326350212097,
      "learning_rate": 4.509334315892901e-05,
      "loss": 0.1013,
      "step": 800
    },
    {
      "epoch": 0.31319086219602066,
      "grad_norm": 0.3779612183570862,
      "learning_rate": 4.478629329403095e-05,
      "loss": 0.1049,
      "step": 850
    },
    {
      "epoch": 0.3316138540899042,
      "grad_norm": 0.35356688499450684,
      "learning_rate": 4.4479243429132895e-05,
      "loss": 0.0976,
      "step": 900
    },
    {
      "epoch": 0.35003684598378776,
      "grad_norm": 0.34360992908477783,
      "learning_rate": 4.4172193564234834e-05,
      "loss": 0.0999,
      "step": 950
    },
    {
      "epoch": 0.36845983787767134,
      "grad_norm": 0.46647870540618896,
      "learning_rate": 4.386514369933677e-05,
      "loss": 0.0952,
      "step": 1000
    },
    {
      "epoch": 0.3868828297715549,
      "grad_norm": 0.4135986566543579,
      "learning_rate": 4.355809383443871e-05,
      "loss": 0.0966,
      "step": 1050
    },
    {
      "epoch": 0.4053058216654385,
      "grad_norm": 0.3083452582359314,
      "learning_rate": 4.325104396954066e-05,
      "loss": 0.0947,
      "step": 1100
    },
    {
      "epoch": 0.423728813559322,
      "grad_norm": 0.33979305624961853,
      "learning_rate": 4.29439941046426e-05,
      "loss": 0.0928,
      "step": 1150
    },
    {
      "epoch": 0.4421518054532056,
      "grad_norm": 0.37417757511138916,
      "learning_rate": 4.2636944239744536e-05,
      "loss": 0.0969,
      "step": 1200
    },
    {
      "epoch": 0.46057479734708917,
      "grad_norm": 0.43941566348075867,
      "learning_rate": 4.232989437484648e-05,
      "loss": 0.0989,
      "step": 1250
    },
    {
      "epoch": 0.47899778924097275,
      "grad_norm": 0.4431043863296509,
      "learning_rate": 4.2022844509948414e-05,
      "loss": 0.0932,
      "step": 1300
    },
    {
      "epoch": 0.4974207811348563,
      "grad_norm": 0.4005314111709595,
      "learning_rate": 4.171579464505036e-05,
      "loss": 0.0975,
      "step": 1350
    },
    {
      "epoch": 0.5158437730287398,
      "grad_norm": 0.3755820393562317,
      "learning_rate": 4.14087447801523e-05,
      "loss": 0.0987,
      "step": 1400
    },
    {
      "epoch": 0.5342667649226235,
      "grad_norm": 0.4217405617237091,
      "learning_rate": 4.110169491525424e-05,
      "loss": 0.0955,
      "step": 1450
    },
    {
      "epoch": 0.552689756816507,
      "grad_norm": 0.36310938000679016,
      "learning_rate": 4.079464505035618e-05,
      "loss": 0.0934,
      "step": 1500
    },
    {
      "epoch": 0.5711127487103905,
      "grad_norm": 0.48594945669174194,
      "learning_rate": 4.048759518545812e-05,
      "loss": 0.0933,
      "step": 1550
    },
    {
      "epoch": 0.5895357406042742,
      "grad_norm": 0.4891525208950043,
      "learning_rate": 4.018054532056006e-05,
      "loss": 0.0947,
      "step": 1600
    },
    {
      "epoch": 0.6079587324981577,
      "grad_norm": 0.4550248980522156,
      "learning_rate": 3.9873495455662e-05,
      "loss": 0.0933,
      "step": 1650
    },
    {
      "epoch": 0.6263817243920413,
      "grad_norm": 0.3626987636089325,
      "learning_rate": 3.956644559076394e-05,
      "loss": 0.0975,
      "step": 1700
    },
    {
      "epoch": 0.6448047162859248,
      "grad_norm": 0.42668724060058594,
      "learning_rate": 3.9259395725865886e-05,
      "loss": 0.0909,
      "step": 1750
    },
    {
      "epoch": 0.6632277081798084,
      "grad_norm": 0.3473604619503021,
      "learning_rate": 3.895234586096782e-05,
      "loss": 0.0877,
      "step": 1800
    },
    {
      "epoch": 0.681650700073692,
      "grad_norm": 0.3361026644706726,
      "learning_rate": 3.8645295996069764e-05,
      "loss": 0.0876,
      "step": 1850
    },
    {
      "epoch": 0.7000736919675755,
      "grad_norm": 0.3166762590408325,
      "learning_rate": 3.833824613117171e-05,
      "loss": 0.0891,
      "step": 1900
    },
    {
      "epoch": 0.7184966838614592,
      "grad_norm": 0.3880136013031006,
      "learning_rate": 3.803119626627364e-05,
      "loss": 0.0921,
      "step": 1950
    },
    {
      "epoch": 0.7369196757553427,
      "grad_norm": 0.28278180956840515,
      "learning_rate": 3.772414640137559e-05,
      "loss": 0.0844,
      "step": 2000
    },
    {
      "epoch": 0.7553426676492262,
      "grad_norm": 0.4674396514892578,
      "learning_rate": 3.7417096536477526e-05,
      "loss": 0.0897,
      "step": 2050
    },
    {
      "epoch": 0.7737656595431098,
      "grad_norm": 0.4106282889842987,
      "learning_rate": 3.7110046671579465e-05,
      "loss": 0.0928,
      "step": 2100
    },
    {
      "epoch": 0.7921886514369934,
      "grad_norm": 0.35315218567848206,
      "learning_rate": 3.6802996806681404e-05,
      "loss": 0.0883,
      "step": 2150
    },
    {
      "epoch": 0.810611643330877,
      "grad_norm": 0.34802311658859253,
      "learning_rate": 3.649594694178335e-05,
      "loss": 0.0873,
      "step": 2200
    },
    {
      "epoch": 0.8290346352247605,
      "grad_norm": 0.32627904415130615,
      "learning_rate": 3.618889707688529e-05,
      "loss": 0.0887,
      "step": 2250
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.4145371615886688,
      "learning_rate": 3.588184721198723e-05,
      "loss": 0.0915,
      "step": 2300
    },
    {
      "epoch": 0.8658806190125277,
      "grad_norm": 0.3798576593399048,
      "learning_rate": 3.557479734708917e-05,
      "loss": 0.0893,
      "step": 2350
    },
    {
      "epoch": 0.8843036109064112,
      "grad_norm": 0.3775102198123932,
      "learning_rate": 3.526774748219111e-05,
      "loss": 0.0861,
      "step": 2400
    },
    {
      "epoch": 0.9027266028002948,
      "grad_norm": 0.38785815238952637,
      "learning_rate": 3.4960697617293045e-05,
      "loss": 0.0916,
      "step": 2450
    },
    {
      "epoch": 0.9211495946941783,
      "grad_norm": 0.30472227931022644,
      "learning_rate": 3.465364775239499e-05,
      "loss": 0.0913,
      "step": 2500
    },
    {
      "epoch": 0.9395725865880619,
      "grad_norm": 0.3237028121948242,
      "learning_rate": 3.434659788749693e-05,
      "loss": 0.0874,
      "step": 2550
    },
    {
      "epoch": 0.9579955784819455,
      "grad_norm": 0.41079291701316833,
      "learning_rate": 3.403954802259887e-05,
      "loss": 0.0897,
      "step": 2600
    },
    {
      "epoch": 0.976418570375829,
      "grad_norm": 0.3721165657043457,
      "learning_rate": 3.3732498157700815e-05,
      "loss": 0.0842,
      "step": 2650
    },
    {
      "epoch": 0.9948415622697127,
      "grad_norm": 0.3084867596626282,
      "learning_rate": 3.3425448292802754e-05,
      "loss": 0.086,
      "step": 2700
    },
    {
      "epoch": 1.013264554163596,
      "grad_norm": 0.3416370749473572,
      "learning_rate": 3.311839842790469e-05,
      "loss": 0.0837,
      "step": 2750
    },
    {
      "epoch": 1.0316875460574797,
      "grad_norm": 0.4031254053115845,
      "learning_rate": 3.281134856300663e-05,
      "loss": 0.0809,
      "step": 2800
    },
    {
      "epoch": 1.0501105379513633,
      "grad_norm": 0.3924940526485443,
      "learning_rate": 3.250429869810858e-05,
      "loss": 0.0759,
      "step": 2850
    },
    {
      "epoch": 1.068533529845247,
      "grad_norm": 0.41780829429626465,
      "learning_rate": 3.219724883321052e-05,
      "loss": 0.0753,
      "step": 2900
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 0.3673413395881653,
      "learning_rate": 3.1890198968312456e-05,
      "loss": 0.0799,
      "step": 2950
    },
    {
      "epoch": 1.105379513633014,
      "grad_norm": 0.39127296209335327,
      "learning_rate": 3.1583149103414395e-05,
      "loss": 0.08,
      "step": 3000
    },
    {
      "epoch": 1.1238025055268976,
      "grad_norm": 0.4114629030227661,
      "learning_rate": 3.127609923851634e-05,
      "loss": 0.0795,
      "step": 3050
    },
    {
      "epoch": 1.142225497420781,
      "grad_norm": 0.37445947527885437,
      "learning_rate": 3.096904937361827e-05,
      "loss": 0.079,
      "step": 3100
    },
    {
      "epoch": 1.1606484893146647,
      "grad_norm": 0.40638062357902527,
      "learning_rate": 3.066199950872022e-05,
      "loss": 0.073,
      "step": 3150
    },
    {
      "epoch": 1.1790714812085483,
      "grad_norm": 0.4149155914783478,
      "learning_rate": 3.0354949643822158e-05,
      "loss": 0.0762,
      "step": 3200
    },
    {
      "epoch": 1.1974944731024317,
      "grad_norm": 0.3394641876220703,
      "learning_rate": 3.00478997789241e-05,
      "loss": 0.0766,
      "step": 3250
    },
    {
      "epoch": 1.2159174649963154,
      "grad_norm": 0.4046657085418701,
      "learning_rate": 2.9740849914026036e-05,
      "loss": 0.0772,
      "step": 3300
    },
    {
      "epoch": 1.234340456890199,
      "grad_norm": 0.3142762780189514,
      "learning_rate": 2.943380004912798e-05,
      "loss": 0.0769,
      "step": 3350
    },
    {
      "epoch": 1.2527634487840826,
      "grad_norm": 0.44267043471336365,
      "learning_rate": 2.9126750184229924e-05,
      "loss": 0.0756,
      "step": 3400
    },
    {
      "epoch": 1.271186440677966,
      "grad_norm": 0.5001620650291443,
      "learning_rate": 2.881970031933186e-05,
      "loss": 0.0741,
      "step": 3450
    },
    {
      "epoch": 1.2896094325718497,
      "grad_norm": 0.518670916557312,
      "learning_rate": 2.8512650454433805e-05,
      "loss": 0.0786,
      "step": 3500
    },
    {
      "epoch": 1.3080324244657333,
      "grad_norm": 0.48319536447525024,
      "learning_rate": 2.820560058953574e-05,
      "loss": 0.0748,
      "step": 3550
    },
    {
      "epoch": 1.3264554163596167,
      "grad_norm": 0.4449201226234436,
      "learning_rate": 2.7898550724637683e-05,
      "loss": 0.0796,
      "step": 3600
    },
    {
      "epoch": 1.3448784082535004,
      "grad_norm": 0.4801563322544098,
      "learning_rate": 2.7591500859739622e-05,
      "loss": 0.0793,
      "step": 3650
    },
    {
      "epoch": 1.363301400147384,
      "grad_norm": 0.4075969457626343,
      "learning_rate": 2.7284450994841565e-05,
      "loss": 0.0767,
      "step": 3700
    },
    {
      "epoch": 1.3817243920412676,
      "grad_norm": 0.36368533968925476,
      "learning_rate": 2.6977401129943504e-05,
      "loss": 0.0784,
      "step": 3750
    },
    {
      "epoch": 1.400147383935151,
      "grad_norm": 0.3433031439781189,
      "learning_rate": 2.6670351265045446e-05,
      "loss": 0.0756,
      "step": 3800
    },
    {
      "epoch": 1.4185703758290347,
      "grad_norm": 0.3648483455181122,
      "learning_rate": 2.636330140014738e-05,
      "loss": 0.079,
      "step": 3850
    },
    {
      "epoch": 1.436993367722918,
      "grad_norm": 0.458778977394104,
      "learning_rate": 2.6056251535249327e-05,
      "loss": 0.0772,
      "step": 3900
    },
    {
      "epoch": 1.4554163596168017,
      "grad_norm": 0.3912675678730011,
      "learning_rate": 2.5749201670351263e-05,
      "loss": 0.0787,
      "step": 3950
    },
    {
      "epoch": 1.4738393515106853,
      "grad_norm": 0.36369985342025757,
      "learning_rate": 2.5442151805453205e-05,
      "loss": 0.0772,
      "step": 4000
    },
    {
      "epoch": 1.492262343404569,
      "grad_norm": 0.44539159536361694,
      "learning_rate": 2.5135101940555145e-05,
      "loss": 0.0791,
      "step": 4050
    },
    {
      "epoch": 1.5106853352984526,
      "grad_norm": 0.4041239619255066,
      "learning_rate": 2.4828052075657087e-05,
      "loss": 0.0778,
      "step": 4100
    },
    {
      "epoch": 1.529108327192336,
      "grad_norm": 0.4115881621837616,
      "learning_rate": 2.452100221075903e-05,
      "loss": 0.0765,
      "step": 4150
    },
    {
      "epoch": 1.5475313190862194,
      "grad_norm": 0.46112900972366333,
      "learning_rate": 2.421395234586097e-05,
      "loss": 0.0754,
      "step": 4200
    },
    {
      "epoch": 1.565954310980103,
      "grad_norm": 0.5499988198280334,
      "learning_rate": 2.3906902480962907e-05,
      "loss": 0.078,
      "step": 4250
    },
    {
      "epoch": 1.5843773028739867,
      "grad_norm": 0.40156102180480957,
      "learning_rate": 2.359985261606485e-05,
      "loss": 0.0742,
      "step": 4300
    },
    {
      "epoch": 1.6028002947678703,
      "grad_norm": 0.4001010060310364,
      "learning_rate": 2.329280275116679e-05,
      "loss": 0.0755,
      "step": 4350
    },
    {
      "epoch": 1.621223286661754,
      "grad_norm": 0.5528962016105652,
      "learning_rate": 2.298575288626873e-05,
      "loss": 0.0756,
      "step": 4400
    },
    {
      "epoch": 1.6396462785556374,
      "grad_norm": 0.4362874925136566,
      "learning_rate": 2.2678703021370674e-05,
      "loss": 0.0756,
      "step": 4450
    },
    {
      "epoch": 1.658069270449521,
      "grad_norm": 0.4841185510158539,
      "learning_rate": 2.2371653156472613e-05,
      "loss": 0.0803,
      "step": 4500
    },
    {
      "epoch": 1.6764922623434044,
      "grad_norm": 0.4647367298603058,
      "learning_rate": 2.2064603291574555e-05,
      "loss": 0.0744,
      "step": 4550
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 0.4946751594543457,
      "learning_rate": 2.1757553426676494e-05,
      "loss": 0.0753,
      "step": 4600
    },
    {
      "epoch": 1.7133382461311717,
      "grad_norm": 0.45959699153900146,
      "learning_rate": 2.1450503561778433e-05,
      "loss": 0.0762,
      "step": 4650
    },
    {
      "epoch": 1.7317612380250553,
      "grad_norm": 0.41744178533554077,
      "learning_rate": 2.1143453696880375e-05,
      "loss": 0.0713,
      "step": 4700
    },
    {
      "epoch": 1.750184229918939,
      "grad_norm": 0.3951719105243683,
      "learning_rate": 2.0836403831982314e-05,
      "loss": 0.077,
      "step": 4750
    },
    {
      "epoch": 1.7686072218128224,
      "grad_norm": 0.2959989607334137,
      "learning_rate": 2.0529353967084257e-05,
      "loss": 0.0743,
      "step": 4800
    },
    {
      "epoch": 1.787030213706706,
      "grad_norm": 0.5089824795722961,
      "learning_rate": 2.0222304102186196e-05,
      "loss": 0.0723,
      "step": 4850
    },
    {
      "epoch": 1.8054532056005894,
      "grad_norm": 0.41965609788894653,
      "learning_rate": 1.9915254237288135e-05,
      "loss": 0.0753,
      "step": 4900
    },
    {
      "epoch": 1.823876197494473,
      "grad_norm": 0.45510560274124146,
      "learning_rate": 1.9608204372390077e-05,
      "loss": 0.0728,
      "step": 4950
    },
    {
      "epoch": 1.8422991893883567,
      "grad_norm": 0.43114203214645386,
      "learning_rate": 1.9301154507492016e-05,
      "loss": 0.0726,
      "step": 5000
    },
    {
      "epoch": 1.8607221812822403,
      "grad_norm": 0.5241797566413879,
      "learning_rate": 1.899410464259396e-05,
      "loss": 0.0768,
      "step": 5050
    },
    {
      "epoch": 1.879145173176124,
      "grad_norm": 0.41700518131256104,
      "learning_rate": 1.8687054777695898e-05,
      "loss": 0.0761,
      "step": 5100
    },
    {
      "epoch": 1.8975681650700074,
      "grad_norm": 0.35139063000679016,
      "learning_rate": 1.8380004912797837e-05,
      "loss": 0.0747,
      "step": 5150
    },
    {
      "epoch": 1.9159911569638908,
      "grad_norm": 0.4119851291179657,
      "learning_rate": 1.8072955047899782e-05,
      "loss": 0.0748,
      "step": 5200
    },
    {
      "epoch": 1.9344141488577744,
      "grad_norm": 0.3939853310585022,
      "learning_rate": 1.776590518300172e-05,
      "loss": 0.0746,
      "step": 5250
    },
    {
      "epoch": 1.952837140751658,
      "grad_norm": 0.5656388998031616,
      "learning_rate": 1.745885531810366e-05,
      "loss": 0.073,
      "step": 5300
    },
    {
      "epoch": 1.9712601326455417,
      "grad_norm": 0.5340131521224976,
      "learning_rate": 1.7151805453205603e-05,
      "loss": 0.0741,
      "step": 5350
    },
    {
      "epoch": 1.9896831245394253,
      "grad_norm": 0.3261289596557617,
      "learning_rate": 1.6844755588307542e-05,
      "loss": 0.0747,
      "step": 5400
    },
    {
      "epoch": 2.008106116433309,
      "grad_norm": 0.3397448658943176,
      "learning_rate": 1.6537705723409484e-05,
      "loss": 0.0665,
      "step": 5450
    },
    {
      "epoch": 2.026529108327192,
      "grad_norm": 0.44469135999679565,
      "learning_rate": 1.6230655858511423e-05,
      "loss": 0.0624,
      "step": 5500
    },
    {
      "epoch": 2.0449521002210758,
      "grad_norm": 0.410173624753952,
      "learning_rate": 1.5923605993613362e-05,
      "loss": 0.0641,
      "step": 5550
    },
    {
      "epoch": 2.0633750921149594,
      "grad_norm": 0.3622215688228607,
      "learning_rate": 1.5616556128715305e-05,
      "loss": 0.0623,
      "step": 5600
    },
    {
      "epoch": 2.081798084008843,
      "grad_norm": 0.4679686725139618,
      "learning_rate": 1.5309506263817244e-05,
      "loss": 0.0625,
      "step": 5650
    },
    {
      "epoch": 2.1002210759027267,
      "grad_norm": 0.46619912981987,
      "learning_rate": 1.5002456398919184e-05,
      "loss": 0.0626,
      "step": 5700
    },
    {
      "epoch": 2.1186440677966103,
      "grad_norm": 0.40466782450675964,
      "learning_rate": 1.4695406534021125e-05,
      "loss": 0.0611,
      "step": 5750
    },
    {
      "epoch": 2.137067059690494,
      "grad_norm": 0.43605780601501465,
      "learning_rate": 1.4388356669123066e-05,
      "loss": 0.0626,
      "step": 5800
    },
    {
      "epoch": 2.155490051584377,
      "grad_norm": 0.5324794054031372,
      "learning_rate": 1.4081306804225005e-05,
      "loss": 0.0621,
      "step": 5850
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.3863554000854492,
      "learning_rate": 1.3774256939326946e-05,
      "loss": 0.0607,
      "step": 5900
    },
    {
      "epoch": 2.1923360353721444,
      "grad_norm": 0.3632688522338867,
      "learning_rate": 1.346720707442889e-05,
      "loss": 0.0605,
      "step": 5950
    },
    {
      "epoch": 2.210759027266028,
      "grad_norm": 0.6098573803901672,
      "learning_rate": 1.316015720953083e-05,
      "loss": 0.0609,
      "step": 6000
    },
    {
      "epoch": 2.2291820191599117,
      "grad_norm": 0.4551726281642914,
      "learning_rate": 1.285310734463277e-05,
      "loss": 0.0641,
      "step": 6050
    },
    {
      "epoch": 2.2476050110537953,
      "grad_norm": 0.39258140325546265,
      "learning_rate": 1.254605747973471e-05,
      "loss": 0.0618,
      "step": 6100
    },
    {
      "epoch": 2.266028002947679,
      "grad_norm": 0.4319145679473877,
      "learning_rate": 1.223900761483665e-05,
      "loss": 0.0601,
      "step": 6150
    },
    {
      "epoch": 2.284450994841562,
      "grad_norm": 0.5355328917503357,
      "learning_rate": 1.1931957749938591e-05,
      "loss": 0.0616,
      "step": 6200
    },
    {
      "epoch": 2.3028739867354457,
      "grad_norm": 0.3957505226135254,
      "learning_rate": 1.162490788504053e-05,
      "loss": 0.06,
      "step": 6250
    },
    {
      "epoch": 2.3212969786293294,
      "grad_norm": 0.47489503026008606,
      "learning_rate": 1.1317858020142471e-05,
      "loss": 0.0606,
      "step": 6300
    },
    {
      "epoch": 2.339719970523213,
      "grad_norm": 0.49240732192993164,
      "learning_rate": 1.1010808155244412e-05,
      "loss": 0.062,
      "step": 6350
    },
    {
      "epoch": 2.3581429624170966,
      "grad_norm": 0.4521259069442749,
      "learning_rate": 1.0703758290346353e-05,
      "loss": 0.0577,
      "step": 6400
    },
    {
      "epoch": 2.3765659543109803,
      "grad_norm": 0.40671539306640625,
      "learning_rate": 1.0396708425448293e-05,
      "loss": 0.0625,
      "step": 6450
    },
    {
      "epoch": 2.3949889462048635,
      "grad_norm": 0.4034057557582855,
      "learning_rate": 1.0089658560550234e-05,
      "loss": 0.0552,
      "step": 6500
    },
    {
      "epoch": 2.413411938098747,
      "grad_norm": 0.36710476875305176,
      "learning_rate": 9.782608695652175e-06,
      "loss": 0.0641,
      "step": 6550
    },
    {
      "epoch": 2.4318349299926307,
      "grad_norm": 0.420014888048172,
      "learning_rate": 9.475558830754115e-06,
      "loss": 0.0606,
      "step": 6600
    },
    {
      "epoch": 2.4502579218865144,
      "grad_norm": 0.5037350058555603,
      "learning_rate": 9.168508965856056e-06,
      "loss": 0.0639,
      "step": 6650
    },
    {
      "epoch": 2.468680913780398,
      "grad_norm": 0.5957213640213013,
      "learning_rate": 8.861459100957995e-06,
      "loss": 0.0614,
      "step": 6700
    },
    {
      "epoch": 2.4871039056742816,
      "grad_norm": 0.4803552031517029,
      "learning_rate": 8.554409236059936e-06,
      "loss": 0.0616,
      "step": 6750
    },
    {
      "epoch": 2.5055268975681653,
      "grad_norm": 0.3564956784248352,
      "learning_rate": 8.247359371161877e-06,
      "loss": 0.0609,
      "step": 6800
    },
    {
      "epoch": 2.523949889462049,
      "grad_norm": 0.6022111177444458,
      "learning_rate": 7.940309506263819e-06,
      "loss": 0.0593,
      "step": 6850
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 0.5021968483924866,
      "learning_rate": 7.633259641365758e-06,
      "loss": 0.0623,
      "step": 6900
    },
    {
      "epoch": 2.5607958732498157,
      "grad_norm": 0.45466911792755127,
      "learning_rate": 7.326209776467699e-06,
      "loss": 0.0573,
      "step": 6950
    },
    {
      "epoch": 2.5792188651436994,
      "grad_norm": 0.576568067073822,
      "learning_rate": 7.019159911569639e-06,
      "loss": 0.0619,
      "step": 7000
    },
    {
      "epoch": 2.597641857037583,
      "grad_norm": 0.6122458577156067,
      "learning_rate": 6.71211004667158e-06,
      "loss": 0.0615,
      "step": 7050
    },
    {
      "epoch": 2.6160648489314666,
      "grad_norm": 0.43655088543891907,
      "learning_rate": 6.40506018177352e-06,
      "loss": 0.0633,
      "step": 7100
    },
    {
      "epoch": 2.63448784082535,
      "grad_norm": 0.6096449494361877,
      "learning_rate": 6.0980103168754615e-06,
      "loss": 0.0584,
      "step": 7150
    },
    {
      "epoch": 2.6529108327192334,
      "grad_norm": 0.5975638628005981,
      "learning_rate": 5.790960451977401e-06,
      "loss": 0.0584,
      "step": 7200
    },
    {
      "epoch": 2.671333824613117,
      "grad_norm": 0.5959894061088562,
      "learning_rate": 5.483910587079342e-06,
      "loss": 0.0617,
      "step": 7250
    },
    {
      "epoch": 2.6897568165070007,
      "grad_norm": 0.423652321100235,
      "learning_rate": 5.176860722181282e-06,
      "loss": 0.0621,
      "step": 7300
    },
    {
      "epoch": 2.7081798084008843,
      "grad_norm": 0.4035031795501709,
      "learning_rate": 4.8698108572832235e-06,
      "loss": 0.0609,
      "step": 7350
    },
    {
      "epoch": 2.726602800294768,
      "grad_norm": 0.5445414185523987,
      "learning_rate": 4.562760992385163e-06,
      "loss": 0.0616,
      "step": 7400
    },
    {
      "epoch": 2.7450257921886516,
      "grad_norm": 0.4555397033691406,
      "learning_rate": 4.255711127487104e-06,
      "loss": 0.0613,
      "step": 7450
    },
    {
      "epoch": 2.7634487840825352,
      "grad_norm": 0.539594829082489,
      "learning_rate": 3.948661262589045e-06,
      "loss": 0.059,
      "step": 7500
    },
    {
      "epoch": 2.7818717759764184,
      "grad_norm": 0.5403899550437927,
      "learning_rate": 3.6416113976909855e-06,
      "loss": 0.0548,
      "step": 7550
    },
    {
      "epoch": 2.800294767870302,
      "grad_norm": 0.38164615631103516,
      "learning_rate": 3.3345615327929258e-06,
      "loss": 0.0573,
      "step": 7600
    },
    {
      "epoch": 2.8187177597641857,
      "grad_norm": 0.5193132162094116,
      "learning_rate": 3.0275116678948665e-06,
      "loss": 0.0571,
      "step": 7650
    },
    {
      "epoch": 2.8371407516580693,
      "grad_norm": 0.4791307747364044,
      "learning_rate": 2.7204618029968068e-06,
      "loss": 0.0587,
      "step": 7700
    },
    {
      "epoch": 2.855563743551953,
      "grad_norm": 0.5799540877342224,
      "learning_rate": 2.4134119380987475e-06,
      "loss": 0.0593,
      "step": 7750
    },
    {
      "epoch": 2.873986735445836,
      "grad_norm": 0.6461619138717651,
      "learning_rate": 2.1063620732006878e-06,
      "loss": 0.0566,
      "step": 7800
    },
    {
      "epoch": 2.89240972733972,
      "grad_norm": 0.49492737650871277,
      "learning_rate": 1.7993122083026285e-06,
      "loss": 0.0593,
      "step": 7850
    },
    {
      "epoch": 2.9108327192336034,
      "grad_norm": 0.5310770273208618,
      "learning_rate": 1.492262343404569e-06,
      "loss": 0.0563,
      "step": 7900
    },
    {
      "epoch": 2.929255711127487,
      "grad_norm": 0.5213317275047302,
      "learning_rate": 1.1852124785065094e-06,
      "loss": 0.058,
      "step": 7950
    },
    {
      "epoch": 2.9476787030213707,
      "grad_norm": 0.4744049608707428,
      "learning_rate": 8.7816261360845e-07,
      "loss": 0.0566,
      "step": 8000
    },
    {
      "epoch": 2.9661016949152543,
      "grad_norm": 0.5034796595573425,
      "learning_rate": 5.711127487103905e-07,
      "loss": 0.0583,
      "step": 8050
    },
    {
      "epoch": 2.984524686809138,
      "grad_norm": 0.41712021827697754,
      "learning_rate": 2.6406288381233114e-07,
      "loss": 0.063,
      "step": 8100
    }
  ],
  "logging_steps": 50,
  "max_steps": 8142,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4314807064442880.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
